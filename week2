import pandas as pd
import math
import numpy as np
from google.colab import files
files.upload()
data = pd.read_csv("/content/weather.csv")
features = [feat for feat in data]
features.remove("answer")
class Node:
 def __init__(self):
 self.children = []
 self.value = ""
 self.isLeaf = False 
self.pred = ""
def entropy(examples):
 pos = 0.0
 neg = 0.0
 for _, row in examples.iterrows():
 if row["answer"] == "yes":
 pos += 1
 else:
 neg += 1
 if pos == 0.0 or neg == 0.0:
 return 0.0
 else:
 p = pos / (pos + neg)
 n = neg / (pos + neg)
 return -(p * math.log(p, 2) + n * math.log(n, 2))
def info_gain(examples, attr):
 uniq = np.unique(examples[attr])
 gain = entropy(examples)
 for u in uniq:
 subdata = examples[examples[attr] == u]
 sub_e = entropy(subdata)
 gain -= (float(len(subdata)) / float(len(examples))) * sub_e
 return gain
def ID3(examples, attrs):
 root = Node()
 max_gain = 0
 max_feat = ""
 for feature in attrs:
 gain = info_gain(examples, feature)
 if gain > max_gain:
 max_gain = gain
 max_feat = feature
 root.value = max_feat
 uniq = np.unique(examples[max_feat])
 for u in uniq:
 subdata = examples[examples[max_feat] == u]
 dummyNode.children.append(child)
 root.children.append(dummyNode)
 return root
def printTree(root: Node, depth=0):
 for i in range(depth):
 print("\t", end="")
 print(root.value, end="")
 if root.isLeaf:
 print(" -> ", root.pred)
 print()
 for child in root.children:
 printTree(child, depth + 1) 
def classify(root: Node, new):
 for child in root.children:
 if child.value == new[root.value]:
 print("Predicted Label for new example", new, " is:", child.pred)
 exit
 else:
 classify(child.children[0], new)
root = ID3(data, features)
print("Decision Tree is:")
printTree(root)
print(" ----------------- ")
new = {"outlook":"sunny", "temperature":"hot", "humidity":"normal", "wind":"strong"}
classify(root, new)
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
clf = DecisionTreeClassifier(random_state=0, max_depth=2)
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)
clf.fit(X_train, y_train)
plot_tree(clf)
r = export_text(clf, feature_names=iris['feature_names'])
print(r)
